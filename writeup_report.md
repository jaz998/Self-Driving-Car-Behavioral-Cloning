# **Behavioral Cloning** 

---

**Behavioral Cloning Project**

The goals / steps of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report


---


My project includes the following files:
* model.py containing the script to create and train the model
* drive.py for driving the car in autonomous mode
* model.h5 containing a trained convolution neural network 
* writeup_report.md or writeup_report.pdf summarizing the results


Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing 
```sh
python drive.py model.h5
```



### Model Architecture and Training Strategy

#### 1. Solution Design Approach

I use the nVidea model of [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/deep-learning-self-driving-cars/), which as per nVidea's testing, it enables a car to drive autonomously in a wide-range of road conditions with less than 100 hours of training data. 

In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set on a 80%-20% split. 


On my first model, I used 5 epochs and found that after epoch 3, the validation MSE is sustantial higher then training MSE (0.0281 compared to 0.0189 at epoch 4, and 0.0246 compared to training MSE of 0.0172 ), suggesting that the model is overfitting. 

In order to reduce over-fitting. I then used 3 epochs only to train the model . 

The final step was to run the simulator to see how well the car was driving around track one. There were a few spots where the vehicle fell off the track. To improve the driving behavior in these cases, I created additional data by rotate each image vertically. 

At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.

#### 2. Final Model Architecture

The final model architecture (model.py lines 73-92) consisted of a convolution neural network with the following layers and layer sizes ...
##### Preprocessing Layers
**Lambda Layer**: Normalization
**Cropping2D**: Crop the images

#### Model Layers
**Layer 1**: Convolution2D: filter: 5x5 depth 24, strides: 2x2, activatoin: ReLU

**Layer 2**: Convolution2D: filter: 5x5 depth 36, strides: 2x2, activatoin: ReLU

**Layer 3**: Convolution2D: filter: 5x5 depth 48, strides: 2x2, activatoin: ReLU
**Layer 4**: Convolution2D: filter: 3x3 depth 64, strides: 2x2, activatoin: ReLU
**Layer 5**: Convolution2D: filter: 3x3 depth 64, strides: 2x2, activatoin: ReLU
**Layer 6** Fully-connected: Neurons: 100
**Layer 7** Fully-connected: Neurons: 50
**Layer 8** Fully-connected: Neurons: 10

**The below is the model summary generated by Keras model.summary().

![model summary](/images_writeup/model_summary.png)


#### 3. Creation of the Training Set & Training Process

To capture good driving behavior, I recorded two laps on track one using center lane driving. Here is an example image of center lane driving:

![center_driving_image](/images_writeup/center_image.jpg)



To augment the data sat, I also flipped images vertically for each of the center, left and right camera images. 

After the collection process, I had 26,730 number of data points. I then preprocessed this data by cropping the images to cut out the blue sky and then change the color space from BGR to RGB as the drive.py uses RGB to drive the car. 


I finally randomly shuffled the data set and put 20% of the data into a validation set. 

I used this training data for training the model. The validation set helped determine if the model was over or under fitting. The ideal number of epochs was 3 as evidenced by the screenshot below - it is apparent that after 3 epochs the model overfits (MSE of validation set becomes a lot higher than the MSE of training set).  I used an adam optimizer so that manually training the learning rate wasn't necessary.

![5_epochs_screenshot](/images_writeup/5_epochs.png)


